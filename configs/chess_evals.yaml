project_name: "chess-llm"
experiment_name: "chess_evals"
output_dir: "outputs"
checkpoint_dir: "checkpoints"
log_level: "INFO"

data:
  input_path: "data/chess_evals3.jsonl"
  output_dir: "data"
  batch_size: 1024
  shuffle: true
  train_ratio: 0.90
  num_workers: 16
  seed: 42

model:
  size: "large"
  vocab_size: 32
  embedding_dim: 768
  num_heads: 24
  num_layers: 18
  max_sequence_length: 79
  dropout_rate: 0.1
  use_causal_mask: true

training:
  policy: "state_value"
  learning_rate: 0.0004
  num_steps: 1000000
  warmup_steps: 20000
  batch_size: 512
  gradient_clip_norm: 1.0
  weight_decay: 0.01
  save_frequency: 20000
  log_frequency: 1000
  eval_frequency: 20000
  num_return_buckets: 128
  distributed: true
  num_gpus: 8
  gradient_accumulation_steps: 4

evaluation:
  batch_size: 1024
  num_samples: null
  metrics: ["accuracy", "loss"]
