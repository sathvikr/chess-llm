project_name: "chess-transformer"
experiment_name: "production"
output_dir: "outputs"
checkpoint_dir: "checkpoints"
log_level: "INFO"

data:
  input_path: "data/train.npz"
  output_dir: "data"
  batch_size: 64
  shuffle: true
  train_ratio: 0.9
  num_workers: 8
  seed: 42

model:
  size: "large"
  vocab_size: 32
  embedding_dim: 1024
  num_heads: 8
  num_layers: 16
  max_sequence_length: 79
  dropout_rate: 0.1
  use_causal_mask: true

training:
  policy: "state_value"
  learning_rate: 0.0001
  num_steps: 100000
  warmup_steps: 5000
  batch_size: 64
  gradient_clip_norm: 1.0
  weight_decay: 0.01
  save_frequency: 5000
  log_frequency: 500
  eval_frequency: 2500
  num_return_buckets: 128

evaluation:
  batch_size: 128
  num_samples: null
  metrics: ["accuracy", "loss"]